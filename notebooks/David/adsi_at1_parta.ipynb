{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt \n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect training data\n",
    "df_train = pd.read_csv('../../data/raw/train.csv')\n",
    "#display(df_train)\n",
    "\n",
    "# Import and inspect test data\n",
    "df_test = pd.read_csv('../../data/raw/test.csv')\n",
    "#display(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create profile report\n",
    "profile = ProfileReport(df_train, title=\"Profile Report\", minimal=True)\n",
    "# Export\n",
    "profile.to_file(\"InitialReport.html\")\n",
    "# View\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID column - training data\n",
    "df_train = df_train.drop(['Id_old','Id'], axis=1)\n",
    "\n",
    "# Identify target\n",
    "features = df_train.iloc[:,:-1].to_numpy()\n",
    "target = df_train.iloc[:,-1].to_numpy()\n",
    "\n",
    "# Standardize features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# Save scaler into models folder\n",
    "dump(scaler, '../../models/David/scaler.joblib')\n",
    "\n",
    "# Split into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, target, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample training data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID column - test data\n",
    "df_test = df_test.drop(['Id_old','Id'], axis=1)\n",
    "\n",
    "# Standardize features - test data\n",
    "X_test = scaler.fit_transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save split datasets into data folder\n",
    "#np.save('../../data/processed/X_train', X_train)\n",
    "#np.save('../../data/processed/X_train_res', X_train_res)\n",
    "#np.save('../../data/processed/X_val', X_val)\n",
    "#np.save('../../data/processed/y_train', y_train)\n",
    "#np.save('../../data/processed/y_train_res', y_train_res)\n",
    "#np.save('../../data/processed/y_val', y_val)\n",
    "#np.save('../../data/processed/X_test', X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up experiment space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm_roc(reg):\n",
    "    \n",
    "    # Print confusion matrix to evaluate classification accuracy\n",
    "    plot_confusion_matrix(reg, X_train, y_train, \n",
    "                          cmap=plt.cm.Blues,\n",
    "                          colorbar=False,\n",
    "                          normalize='true')\n",
    "    plt.title(\"Confusion matrix - Training data\")\n",
    "    plt.show() \n",
    "\n",
    "    plot_confusion_matrix(reg, X_val, y_val,\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          colorbar=False,\n",
    "                          normalize='true')\n",
    "    plt.title(\"Confusion matrix - Validation data\")\n",
    "    plt.show() \n",
    "    \n",
    "    # Calculate and plot ROC_AUC\n",
    "    y_score = reg.predict_proba(X_val)[:,1]\n",
    "    roc_auc_val = roc_auc_score(y_val, y_score)\n",
    "    print(\"ROC_AUC:\", roc_auc_val)\n",
    "    reg_disp = plot_roc_curve(reg, X_val, y_val)\n",
    "    \n",
    "    #return reg_disp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_save(reg, name):\n",
    "    \n",
    "    # Fit classifier\n",
    "    reg.fit(X_train, y_train)\n",
    "    print(\"Classifier fit complete.\")\n",
    "    \n",
    "    # Model predictions on training and validation data\n",
    "    y_train_pred = reg.predict(X_train)\n",
    "    y_val_pred = reg.predict(X_val)\n",
    "    print(\"Model predictions complete.\")\n",
    "    \n",
    "    # Save fitted model into model folder\n",
    "    save_path = \"'../../models/David/'\"+name+\"'.joblib'\"\n",
    "    dump(reg,  save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "reg = SVC(kernel = 'linear', probability=True)\n",
    "\n",
    "#linear_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier fit complete.\n",
      "Model predictions complete.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: \"'../../models/David/'linear_svc'.joblib'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-59652a095121>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfit_predict_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'linear_svc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-5b984645687c>\u001b[0m in \u001b[0;36mfit_predict_save\u001b[1;34m(reg, name)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Save fitted model into model folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"'../../models/David/'\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"'.joblib'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\david anker\\.virtualenvs\\mdsi_adsi_feb21_at1-n_gyw-cp\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: \"'../../models/David/'linear_svc'.joblib'\""
     ]
    }
   ],
   "source": [
    "fit_predict_save(reg, 'linear_svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fitted model into model folder\n",
    "dump(linear_svc,  '../../models/David/linear_svc.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions on training and validation data\n",
    "y_train_pred = linear_svc.predict(X_train)\n",
    "y_val_pred = linear_svc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm_roc(linear_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "neigh.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fitted model into model folder\n",
    "dump(neigh,  '../../models/David/neigh_res.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions on training and validation data\n",
    "y_train_pred = neigh.predict(X_train)\n",
    "y_val_pred = neigh.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm_roc(neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fitted model into model folder\n",
    "dump(log_reg,  '../../models/David/log_reg.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions on training and validation data\n",
    "y_train_pred = log_reg.predict(X_train)\n",
    "y_val_pred = log_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm_roc(log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit classifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "log_reg_elastic = LogisticRegression(\n",
    "    penalty='elasticnet', \n",
    "    solver='saga', \n",
    "    l1_ratio=0.5)\n",
    "\n",
    "log_reg_elastic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fitted model into model folder\n",
    "dump(log_reg_elastic,  '../../models/David/log_reg_elastic.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions on training and validation data\n",
    "y_train_pred = log_reg_elastic.predict(X_train)\n",
    "y_val_pred = log_reg_elastic.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm_roc(log_reg_elastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit classifier\n",
    "from sklearn.linear_model import LogisticRegressionCV \n",
    "\n",
    "C_list = np.linspace(0.001, 0.5, 20)\n",
    "\n",
    "log_reg_cv = LogisticRegressionCV(\n",
    "    Cs=C_list, \n",
    "    cv=20,\n",
    "    penalty='l1',\n",
    "    scoring='roc_auc', \n",
    "    solver='liblinear',\n",
    "    tol=1e-4, \n",
    "    max_iter=1000, \n",
    "    class_weight='balanced', \n",
    "    n_jobs=10, #7\n",
    "    verbose=2, \n",
    "    refit=True, \n",
    "    multi_class='ovr', \n",
    "    random_state=42)\n",
    "\n",
    "log_reg_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fitted model into model folder\n",
    "dump(log_reg_cv,  '../../models/David/log_reg_cv.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions on training and validation data\n",
    "y_train_pred = log_reg_cv.predict(X_train)\n",
    "y_val_pred = log_reg_cv.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm_roc(log_reg_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fitted model into model folder\n",
    "dump(random_forest,  '../../models/David/random_forest.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions on training and validation data\n",
    "y_train_pred = random_forest.predict(X_train)\n",
    "y_val_pred = random_forest.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm_roc(random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - second attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest2 = RandomForestClassifier(\n",
    "    n_estimators=5, \n",
    "    criterion='entropy', \n",
    "    max_depth=15, \n",
    "    min_samples_split=3, \n",
    "    random_state=42, \n",
    "    verbose=1, \n",
    "    class_weight='balanced' \n",
    ")\n",
    "\n",
    "random_forest2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fitted model into model folder\n",
    "dump(random_forest2,  '../../models/David/random_forest2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions on training and validation data\n",
    "y_train_pred = random_forest2.predict(X_train)\n",
    "y_val_pred = random_forest2.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm_roc(random_forest2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='sigmoid', probability=True)\n",
    "\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fitted model into model folder\n",
    "dump(svm,  '../../models/David/svm.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions on training and validation data\n",
    "y_train_pred = svm.predict(X_train)\n",
    "y_val_pred = svm.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm_roc(svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and export test data predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target probabilities (use specific model name)\n",
    "test_probs = random_forest2.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe object\n",
    "test_probs_df = pd.DataFrame(test_probs, columns = [\"TARGET_5Yrs\"])\n",
    "\n",
    "# Name 'ID' column\n",
    "test_probs_df.index.name = \"Id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output to csv\n",
    "test_probs_df.to_csv(\"final2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
